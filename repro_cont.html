<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Building reproducible analytical pipelines with R - 14&nbsp; Reproducible analytical pipelines with Docker</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ci_cd.html" rel="next">
<link href="./targets.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script data-goatcounter="https://brodriguesco.goatcounter.com/count" async="" src="//gc.zgo.at/count.js"></script>
<noscript>
    </noscript></head><body class="nav-sidebar floating"><img src="https://brodriguesco.goatcounter.com/count?p=/test-noscript">



<link rel="stylesheet" href="epub.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part2_intro.html">Part 2: Write IT down</a></li><li class="breadcrumb-item"><a href="./repro_cont.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Reproducible analytical pipelines with Docker</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Building reproducible analytical pipelines with R</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/b-rodrigues/rap4all" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Building-reproducible-analytical-pipelines-with-R.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Building-reproducible-analytical-pipelines-with-R.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part1_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 1: Don’t Repeat Yourself</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prerequisites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Before we start</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./project_start.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Project start</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./git.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Version control with Git</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./github.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Collaborating using Trunk-based development</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fprog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Functional programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lit_prog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Literate programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part1_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Conclusion of part 1</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part2_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part 2: Write IT down</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./project_rewrite.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Rewriting our project</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./repro_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Basic reproducibility: freezing packages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Packaging your code</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Testing your code</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./targets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Build automation with targets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./repro_cont.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Reproducible analytical pipelines with Docker</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ci_cd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Continuous integration and continuous deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part2_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Conclusion of part 2</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./book_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">The end</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-docker" id="toc-what-is-docker" class="nav-link active" data-scroll-target="#what-is-docker"><span class="header-section-number">14.1</span> What is Docker?</a></li>
  <li><a href="#a-primer-on-linux" id="toc-a-primer-on-linux" class="nav-link" data-scroll-target="#a-primer-on-linux"><span class="header-section-number">14.2</span> A primer on Linux</a></li>
  <li><a href="#first-steps-with-docker" id="toc-first-steps-with-docker" class="nav-link" data-scroll-target="#first-steps-with-docker"><span class="header-section-number">14.3</span> First steps with Docker</a></li>
  <li><a href="#the-rocker-project" id="toc-the-rocker-project" class="nav-link" data-scroll-target="#the-rocker-project"><span class="header-section-number">14.4</span> The Rocker project</a></li>
  <li><a href="#dockerizing-projects" id="toc-dockerizing-projects" class="nav-link" data-scroll-target="#dockerizing-projects"><span class="header-section-number">14.5</span> Dockerizing projects</a></li>
  <li><a href="#dockerizing-development-environments" id="toc-dockerizing-development-environments" class="nav-link" data-scroll-target="#dockerizing-development-environments"><span class="header-section-number">14.6</span> Dockerizing development environments</a>
  <ul class="collapse">
  <li><a href="#creating-a-base-image-for-development" id="toc-creating-a-base-image-for-development" class="nav-link" data-scroll-target="#creating-a-base-image-for-development"><span class="header-section-number">14.6.1</span> Creating a base image for development</a></li>
  <li><a href="#sharing-images-through-docker-hub" id="toc-sharing-images-through-docker-hub" class="nav-link" data-scroll-target="#sharing-images-through-docker-hub"><span class="header-section-number">14.6.2</span> Sharing images through Docker Hub</a></li>
  <li><a href="#sharing-a-compressed-archive-of-your-image" id="toc-sharing-a-compressed-archive-of-your-image" class="nav-link" data-scroll-target="#sharing-a-compressed-archive-of-your-image"><span class="header-section-number">14.6.3</span> Sharing a compressed archive of your image</a></li>
  </ul></li>
  <li><a href="#some-issues-of-relying-on-docker" id="toc-some-issues-of-relying-on-docker" class="nav-link" data-scroll-target="#some-issues-of-relying-on-docker"><span class="header-section-number">14.7</span> Some issues of relying on Docker</a>
  <ul class="collapse">
  <li><a href="#the-problems-of-relying-so-much-on-docker" id="toc-the-problems-of-relying-so-much-on-docker" class="nav-link" data-scroll-target="#the-problems-of-relying-so-much-on-docker"><span class="header-section-number">14.7.1</span> The problems of relying so much on Docker</a></li>
  <li><a href="#is-docker-enough" id="toc-is-docker-enough" class="nav-link" data-scroll-target="#is-docker-enough"><span class="header-section-number">14.7.2</span> Is Docker enough?</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">14.8</span> Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/b-rodrigues/rap4all/edit/main/repro_cont.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Reproducible analytical pipelines with Docker</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>If the book ended at the end of the previous chapter, it would have been titled “Building analytical pipelines with R”, because we have not ensured that the pipeline we built is reproducible. We did our best though:</p>
<ul>
<li>we used functional and literate programming;</li>
<li>we documented, tested and versioned the code;</li>
<li>we used <code>{renv}</code> to record the dependencies of the project;</li>
<li>the project was rewritten as a <code>{targets}</code> pipeline and re-running it is as easy as it can possibly get.</li>
</ul>
<p>But there are still many variables that we need to consider. If we go back to the reproducibility iceberg, you will notice that we can still go deeper. As the code stands now, we did our best using programming paradigms and libraries, but now we need to consider other aspects.</p>
<p>As already mentioned in the introduction and Chapter 10, <code>{renv}</code> <em>only</em> restores package versions. The R version used for the analysis only gets recorded. So to make sure that the pipeline reproduces the same results, you’d need to install the same R version that was used to build the pipeline originally. But installing the right R version can be difficult sometimes; it depends on the operating system you want to install it on, and how old a version we’re talking about. Installing R 4.0 on Windows should be quite easy, but I wouldn’t be very keen on trying to install R 2.15.0 (released on March 2012) on a current Linux distribution (and it might be problematic even on Windows as well).</p>
<p>Next comes the operating system on which the pipeline was developed. In practice, this rarely matters, but there have been cases where the same code produces different results on different operating systems, sometimes even on different versions of the same operating system!</p>
<p>And finally, I believe that we are in a transition period when it comes to hardware architecture. Apple will very likely completely switch over to an ARM architecture with their Apple silicon CPUs (as of writing, the Mac Pro is the only computer manufactured by Apple that doesn’t use an Apple silicon CPU and only because it was released in 2019) and it wouldn’t surprise me if other manufacturers follow suit and develop their own ARM cpus. This means that projects written today may not run anymore in the future, because of this architecture changes. Libraries compiled for current architectures would need to be recompiled for ARM, and that may be difficult.</p>
<p>So, as I explained in the previous chapter, we want our pipeline to be the composition of pure functions. Nothing in the global environment (apart from <code>{target}</code>-specific options) should influence the runs of the pipeline. But, what about the environment R is running in? The R engine is itself running in some kind of environment. This is what I’ve explained above: operating system (and all the math libraries that are included in the OS that R relies on to run code) and hardware are variables that need to be recorded and/or frozen as much as possible.</p>
<p>Think about it this way: when you running a pure function <code>f()</code> of one argument you think you do this:</p>
<pre><code>f(1)</code></pre>
<p>but actually what you’re doing is:</p>
<pre><code>f(1, "windows 10 - build 22H2 - patch 10.0.19045.2075", 
  "intel x86_64 cpu i9-13900F", 
  "R version 4.2.2")</code></pre>
<p>and so on. <code>f()</code> is only pure as far as the R version currently running <code>f()</code> is concerned. But everything else should also be taken into account! Remember, in technical terms, this means that our function is not referentially transparent.</p>
<p>To deal with this, I will now teach you how to use Docker. Docker will essentially allow you to turn your pipeline referentially transparent, by freezing R’s and the operating system’s versions (and the CPU architecture as well).</p>
<p>Before continuing, let me warn you: if you’re using an Apple computer with an Apple Silicon CPU (M1 or M2), then you may have issues following along. I don’t own such a machine so I cannot test if the code below works flawlessly. What I can say is that I’ve read some users of these computers have had trouble using Docker in the past. These issues might have been solved in the meantime. It seems that enabling the option “use Rosetta for x86/amd64 emulation on Apple Silicon” in Docker Desktop (I will discuss Docker Desktop briefly in the following sections) may solve the issue.</p>
<section id="what-is-docker" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="what-is-docker"><span class="header-section-number">14.1</span> What is Docker?</h2>
<p>Let me first explain in very simple terms what Docker is.</p>
<p>In very simple (and technically wrong) terms, Docker makes it easy to run a Linux virtual machine (VM) on your computer. A VM is a computer within a computer: the idea is that you turn on your computer, start Windows (the operating system you use every day), but then start Ubuntu (a very popular Linux distribution) as if it were any other app installed on your computer and use it (almost) as you would normally. This is what a classic VM solution like <em>Virtualbox</em> offers you. You can start and use Ubuntu interactively from within Windows. This can be quite useful for testing purposes for example.</p>
<p>The way Docker differs from Virtualbox (or VMware) is that it strips down the VM to its bare essentials. There’s no graphical user interface for example, and you will not (typically) use a Docker VM interactively. What you will do instead is write down in a text file the specifications of the VM you want. Let’s call this text file a <em>Dockerfile</em>. For example, you want the VM to be based on Ubuntu. So that would be the first line in the Dockerfile. You then want it to have R installed. So that would be the second line. Then you need to install R packages, so you add those lines as well. Maybe you need to add some system dependencies? Add them. Finally, you add the code of the pipeline that you want to make reproducible as well.</p>
<p>Once you’re done, you have this text file, the Dockerfile, with a complete recipe to generate a Docker VM. That VM is called an <em>image</em> (as I said previously it’s technically not a true VM, but let’s not discuss this). So you have a text file, and this file helps you define and generate an image. Here, you should already see a first advantage of using Docker over a more traditional VM solution like Virtualbox: you can very easily write these Dockerfiles and version them. You can easily start off from another Dockerfile from another project and adapt it to your current pipeline. And most importantly, because everything is written down, it’s reproducible (but more on that at the end of this chapter…).</p>
<p>Ok, so you have this image. This image will be based on some Linux distribution, very often Ubuntu. It comes with a specific version of Ubuntu, and you can add to it a specific version of R. You can also download a specific version of all the packages required for your pipeline. You end up with an environment that is tailor-made for your pipeline. You can then run the pipeline with this Docker image, and <em>always get exactly the same results, ever</em>. This is because, regardless of how, where or when you will run this <em>dockerized</em> pipeline, the same version of R, with the same version of R packages, on the same Linux distribution will be used to reproduce the results of your pipeline. By the way, when you run a Docker image, as in, you’re executing your pipeline inside that container, this now is referred to as a Docker container.</p>
<p>So: a Dockerfile defines a Docker image, from which you can then run containers. I hope that the pictures below will help. The first picture shows what happens when you run the same pipeline on two different R versions and two different operating systems:</p>
<figure class="figure">
<img src="images/without_docker.png" alt="Running a pipeline without Docker results (potentially) in different outputs." class="figure-img">
<figcaption class="figure-caption">
Running a pipeline without Docker results (potentially) in different outputs.
</figcaption>
</figure>
<p>Take a close look at the output, you will notice it’s different!</p>
<p>Now, you run the same pipeline, which is now <em>dockerized</em>:</p>
<figure class="figure">
<img src="images/with_docker.png" alt="Running a pipeline with Docker results in the same outputs." class="figure-img">
<figcaption class="figure-caption">
Running a pipeline with Docker results in the same outputs.
</figcaption>
</figure>
<p>Another way of looking at a Docker image: it’s an immutable sandbox, where the rules of the game are always the same. It doesn’t matter where or when you run this sandbox, the pipeline will always be executed in this same, well-defined space. Because the pipeline runs on the same versions of R (and packages) and on the same operating system defined within the Docker image, our pipeline is now truly reproducible.</p>
<p>But why Linux though; why isn’t it possible to create Docker images based on Windows or macOS? Remember in the introduction, where I explained what reproducibility is? I wrote:</p>
<blockquote class="blockquote">
<p>Open source is a hard requirement for reproducibility.</p>
</blockquote>
<p>Open source is not just a requirement for the programming language used for building the pipeline but extends to the operating system that the pipeline runs on as well. So the reason Docker uses Linux is because you can use Linux distributions like Ubuntu for free and without restrictions. There aren’t any licenses that you need to buy or activate, and Linux distributions can be customized for any use case imaginable. Thus Linux distributions are the only option available to Docker for this task.</p>
</section>
<section id="a-primer-on-linux" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="a-primer-on-linux"><span class="header-section-number">14.2</span> A primer on Linux</h2>
<p>Up until this point, you could have followed along using any operating system. Most of the code shown in this book is R code, so it doesn’t matter on what operating system you’re running it. But there was some code that I ran in the Linux console (for example, I’ve used <code>ls</code> to list files). These commands should also work on macOS, and some even on Windows (<code>ls</code> also works on the Windows command prompt, and in Powershell as well). Instead of using the command line, you could have followed along using the user interface of your operating system as well. For example, in Chapter 11, I list the contents of the <code>dev/</code> directory using the following command:</p>
<pre><code>owner@localhost ➤ ls dev/</code></pre>
<p>but you could have just opened the <code>dev/</code> folder in the file explorer of your operating system of choice. But to use Docker, you will need to get to know Linux and the Linux ecosystem and concepts a little bit. No worries, it’s not as difficult as it sounds, and I think that you likely aren’t afraid of difficult things, or else you would have stopped reading this book much earlier.</p>
<p><em>Linux</em> is not the name of any one specific operating system, but of an operating system kernel. A kernel is an important component of an operating system. What sets the Linux kernel apart from the one used for Windows or macOS, is that the Linux kernel is open-source and free software. So anyone can take that kernel, and add all the other components needed to build a complete operating system. This is why there are many <em>Linux distributions</em>: a Linux distribution is a complete operating system that uses Linux as its kernel. The most popular Linux distribution is called Ubuntu, and if one time you googled something along the lines of “easy linux os for beginners” the answer that came out on top was likely Ubuntu, or one of the other variants of Ubuntu (yes, because Ubuntu itself is also open-source and free software, it is possible to build a variant using Ubuntu as a basis, like Linux Mint).</p>
<p>To define our Docker images, we will be using Ubuntu as a base. The Ubuntu operating system has two releases a year, one in April and one in October. On even years, the April release is long-term support (LTS) release. LTS releases get security updates for 5 years, and Docker images generally use an LTS release as a base. As of writing (May 2023), the current LTS is Ubuntu 22.04 <em>Jammy Jellyfish</em> (Ubuntu releases are named with a number of the form YY.MM and then a code name based on some animal).</p>
<p>If you want, you can install Ubuntu on your computer. But there’s no need for this, since you can use Docker to ship your projects!</p>
<p>A major difference between Ubuntu (and other Linux distributions) and macOS and Windows is how you install software. In short, software for Linux distributions is distributed as packages. If you want to install, say, the Emacs text editor, you can run the following command in the terminal:</p>
<pre><code>sudo apt-get install emacs-gtk</code></pre>
<p>Let’s break this down: <code>sudo</code> makes the next commands run as root. <em>root</em> is Linux jargon for the administrator account. So if I type <code>sudo xyz</code>, the command <code>xyz</code> will run with administrator privileges. Then comes <code>apt-get install</code>. <code>apt-get</code> is Ubuntu’s package manager, and <code>install</code> is the command that installs <code>emacs-gtk</code>. <code>emacs-gtk</code> is the name of the Emacs package. Because you’re an R user, this should be somewhat familiar: after all, extensions for R are also installed using a package manager and a command: <code>install.packages("package_name")</code>. Just like in R, where the packages get downloaded from CRAN, Ubuntu downloads packages from a repository which you can browse <a href="https://packages.ubuntu.com/jammy/">here</a>. Of course, because using the command line is intimidating for beginners, it is also possible to install packages using a software store, just like on macOS or Windows. But remember, Docker only uses what it absolutely needs to function, so there’s no interactive user interface. This is not because Docker’s developers don’t like user interfaces, but because the point of Docker is not to use Docker images interactively, so there’s no need for the user interface. So you need to know how to install Ubuntu packages with the command line.</p>
<p>Just like for R, it is possible to install software from different sources. It is possible to add different repositories, and install software from there. We are not going to use this here, but just as an aside, if you are using Ubuntu on your computer as your daily driver operating system, you really should check out <a href="https://github.com/eddelbuettel/r2u">r2u</a>, an Ubuntu repository that comes with pre-compiled R packages that can get installed, very, very quickly. Even though we will not be using this here (and I’ll explain why later in this chapter), you should definitely consider <code>r2u</code> to provide binary R packages if you use Ubuntu as your daily operating system.</p>
<p>Let’s suppose that you are using Ubuntu on your machine, and are using R. If you want to install the <code>{dplyr}</code> R package, something interesting happens when you type:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"dplyr"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On Windows and macOS, a compiled binary gets downloaded from CRAN and installed on your computer. A “binary” is the compiled source code of the package. Many R packages come with C++ or Fortran code, and this code cannot be used as is by R. So these bits of C++ and Fortran code need to be compiled to be used. Think of it this way: if the source code is the ingredients of a recipe, the compiled binary is the cooked meal. Now imagine that each time you want to eat Bouillabaisse, you have to cook it yourself… or you could get it delivered to your home. You’d probably go for the delivery (especially if it would be free) instead of cooking it each time. But this supposes that there are people out there cooking Bouillabaisse for you. CRAN essentially cooks the package source codes into binaries for Windows and macOS, as shown below:</p>
<figure class="figure">
<img src="images/tidyverse_packages.png" alt="Download links to pre-compiled tidyverse binaries." class="figure-img">
<figcaption class="figure-caption">
Download links to pre-compiled tidyverse binaries.
</figcaption>
</figure>
<p>In the image above, you can see links to compiled binaries of the <code>{tidyverse}</code> package for Windows and macOS, but none for any Linux distribution. This is because, as stated in the introduction, there are many, many, many Linux distributions. So at best, CRAN could offer binaries for Ubuntu, but Ubuntu is not the only Linux distribution, and Ubuntu has two releases a year, which means that every CRAN package (that needs compilation) would need to get compiled twice a year. This is a huge undertaking unless CRAN decided to only offer binaries for LTS releases. But that would still be every two years.</p>
<p>So instead, what happens, is that the burden of compilation is pushed to the user. Every time you type <code>install.packages("package_name")</code>, and if that package requires compilation, that package gets compiled on your machine which not only takes some time, but can also fail. This is because very often, R packages that require compilation need some additional system-level dependencies that need to be installed. For example, here are the Ubuntu dependencies that need to be installed for the installation of the <code>{tidyverse}</code> package to succeed:</p>
<pre><code>libicu-dev
zlib1g-dev
make
libcurl4-openssl-dev
libssl-dev
libfontconfig1-dev
libfreetype6-dev
libfribidi-dev
libharfbuzz-dev
libjpeg-dev
libpng-dev
libtiff-dev
pandoc
libxml2-dev</code></pre>
<p>This why r2u is so useful: by adding this repository, what you’re essentially doing is telling R to not fetch the packages from CRAN, but from the r2u repository. And this repository contains compiled R packages for Ubuntu. So the required system-level dependencies get installed automatically and the R package doesn’t need compilation. So installation of the <code>{tidyverse}</code> package takes less than half a minute on a modern machine.</p>
<p>But if r2u is so nice, why did I say above that we would not be using it? Unfortunately, this is because r2u does not archive compiled binaries of older packages, and this is exactly what we need for reproducibility. So when you’re building a Docker image to make a project reproducible, because that image will be based on Ubuntu, we will need to make sure that our Docker image contains the right system-level dependencies so that compilation of the R packages doesn’t fail. Thankfully, you’re reading the right book.</p>
</section>
<section id="first-steps-with-docker" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="first-steps-with-docker"><span class="header-section-number">14.3</span> First steps with Docker</h2>
<p>Let’s start by creating a “Hello World” Docker image. As I explained in the beginning, to define a Docker image, we need to create a Dockerfile with some instructions. But first, you need of course to install Docker. To install Docker on any operating system (Windows, macOS or Ubuntu or other Linuxes), you can install <a href="https://docs.docker.com/desktop/">Docker Desktop</a>. If you’re running Ubuntu (or another Linux distribution) and don’t want the GUI, you could install the <a href="https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository">Docker engine</a> and then follow the post-installation <a href="https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user">steps for Linux</a> instead.</p>
<p>In any case, whatever operating system you’re using, we will be using the command line to interact with Docker. Once you’re done with installing Docker, create a folder somewhere on your computer, and create inside of this folder an empty text file with the name “Dockerfile”. This can be tricky on Windows, because you have to remove the <code>.txt</code> extension that gets added by default. You might need to turn on the option “File name extensions” in the <code>View</code> pane of the Windows file explorer to make this process easier. Then, open this file with your favourite text editor, and add the following lines:</p>
<pre><code>FROM ubuntu:jammy

RUN uname -a</code></pre>
<p>This very simple Dockerfile does two things: it starts by stating that it’s based on the Ubuntu Jammy (so version 22.04) operating system, and then runs the <code>uname -a</code> command. This command, which gets run inside the Ubunu command line, prints the Linux kernel version from that particular Ubuntu release. <code>FROM</code> and <code>RUN</code> are Docker commands; there are a couple of others that we will discover a bit later. Now, what do you do with this Dockerfile? Remember, a Dockerfile defines an image. So now, we need to build this image to run a container. Open a terminal/command prompt in the folder where the Dockerfile is and type the following:</p>
<pre><code>owner@localhost ➤ docker build -t raps_hello .</code></pre>
<p>The <code>docker build</code> command builds an image from the Dockerfile that is in the path <code>.</code> (a single <code>.</code> means “this current working directory”). The <code>-t</code> option tags that image with the name <code>raps_hello</code>. If everything goes well, you should see this output:</p>
<pre><code>Sending build context to Docker daemon  2.048kB
Step 1/2 : FROM ubuntu:jammy
 ---&gt; 08d22c0ceb15
Step 2/2 : RUN uname -a
 ---&gt; Running in 697194b9a519
Linux 697194b9a519 6.2.6-1-default #1 SMP PREEMPT_DYNAMIC 
     Mon Mar 13 18:57:27 UTC 2023 (fa1a4c6) x86_64 x86_64 x86_64 GNU/Linux
Removing intermediate container 697194b9a519
 ---&gt; a0ea59f23d01
Successfully built a0ea59f23d01
Successfully tagged raps_hello:latest</code></pre>
<p>Look at <code>Step 2/2</code>: you should see the output of the <code>uname -a</code> command:</p>
<pre><code>Linux 697194b9a519 6.2.6-1-default #1 SMP PREEMPT_DYNAMIC
     Mon Mar 13 18:57:27 UTC 2023 (fa1a4c6) x86_64 x86_64 x86_64 GNU/Linux</code></pre>
<p>Every <code>RUN</code> statement in the Dockerfile gets executed at build time: so this is what we will use to install R and needed packages. This way, once the image is built, we end up with an image that contains all the software we need.</p>
<p>Now, we would like to be able to use this image. Using a built image, we can start one or several containers that we can use for whatever we want. Let’s now create a more realistic example. Let’s build a Docker image that comes with R pre-installed. But for this, we need to go back to our Dockerfile and change it a bit:</p>
<pre><code>FROM ubuntu:jammy

ENV TZ=Europe/Luxembourg

RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone

RUN apt-get update &amp;&amp; apt-get install -y r-base

CMD ["R"]</code></pre>
<p>First we define a variable using <code>ENV</code>, called <code>TZ</code> and we set that to the <code>Europe/Luxembourg</code> time zone (you can change this to your own time zone). We then run a rather complex looking command that sets the defined time zone system-wide. We had to do all this, because when we will later install R, a system-level dependency called <code>tzdata</code> gets installed alongside it. This tool then asks the user to enter his or her time zone interactively. But we cannot interact with the image interactively as it’s being built, so the build process gets stuck at this prompt. By using these two commands, we can set the correct time zone and once <code>tzdata</code> gets installed, that tool doesn’t ask for the time zone anymore, so the build process can continue. This is a rather known issue when building Docker images based on Ubuntu, so the fix is easily found with a Google search (but I’m giving it to you, dear reader, for free).</p>
<p>Then come <code>RUN</code> statements. The first one uses Ubuntu’s package manager to first refresh the repositories (this ensures that our local Ubuntu installation repositories are in synch with the latest software updates that were pushed to the central Ubuntu repos). Then we use Ubuntu’s package manager to install <code>r-base</code>. <code>r-base</code> is the package that installs R. We then finish this Dockerfile by running <code>CMD ["R"]</code>. This is the command that will be executed when we run the container. Remember: <code>RUN</code> commands get executed at build-time, <code>CMD</code> commands at run-time. This distinction will be important later on.</p>
<p>Let’s build the image (this will take some time, because a lot of software gets installed):</p>
<pre><code>owner@localhost ➤ docker build -t raps_ubuntu_r .</code></pre>
<p>This builds an image called <code>raps_ubuntu_r</code>. This image is based on Ubuntu 22.04 Jammy Jellyfish and comes with R pre-installed. But the version of R that gets installed is the one made available through the Ubuntu repositories, and as of writing that is version 4.1.2, while the latest version available is R version 4.2.3. So the version available through the Ubuntu repositories lags behind the actual release. But no matter, we will deal with that later.</p>
<p>We can now start a container with the following command:</p>
<pre><code>owner@localhost ➤ docker run raps_ubuntu_r</code></pre>
<p>And this is the output we get:</p>
<pre><code>Fatal error: you must specify '--save', '--no-save' or '--vanilla'</code></pre>
<p>What is going on here? When you run a container, the command specified by <code>CMD</code> gets executed, and then the container quits. So here, the container ran the command <code>R</code>, which started the R interpreter, but then quit immediately. When quitting R, users should specify if they want to save or not save the workspace. This is what the message above is telling us. So, how can be use this? Is there a way to use this R version interactively?</p>
<p>Yes, there is a way to use this R version boxed inside our Docker image interactively, even though that’s not really what we want to achieve. What we want instead is that our pipeline gets executed when we run the container. We don’t want to mess with the container interactively. But let me show you how we can interact with this dockerized R version. First, you need to let the container run in the background. You can achieve this by running the following command:</p>
<pre><code>owner@localhost ➤ docker run -d -it --name ubuntu_r_1 raps_ubuntu_r</code></pre>
<p>This runs the container that we name “ubuntu_r_1” from the image “raps_ubuntu_r” (remember that we can run many containers from one single image definition). Thanks to the option <code>-d</code>, the container runs in the background, and the option <code>-it</code> states that we want an interactive shell to be waiting for us. So the container runs in the background, with an interactive shell waiting for us, instead of launching (and then immediately stopping) the R command. You can now “connect” to the interactive shell and start R in it using:</p>
<pre><code>owner@localhost ➤ docker exec -it ubuntu_r_1 R</code></pre>
<p>You should now see the familiar R prompt:</p>
<pre><code>R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

&gt; </code></pre>
<p>Welcome to a dockerized version of R. Now, all of this might have felt overly complicated to you. And of course if this is the first time that you have played around with Docker, it is tricky indeed. However, you shouldn’t worry too much about it, for several reasons:</p>
<ul>
<li>we are not going to use Docker containers interactively, that’s not really the point, but it can be useful to log in into the running container to check if things are working as expected;</li>
<li>we will build our images on top of pre-built images from the <a href="https://rocker-project.org/">Rocker project</a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and these images come with a lot of software pre-installed and configuration taken care of.</li>
</ul>
<p>What you should take away from this section is that you need to write a Dockerfile which then allows you to build an image. This image can then be used to run one (or several) containers. These containers, at run-time, will execute our pipeline in an environment that is frozen, such that the output of this run will stay constant, forever.</p>
</section>
<section id="the-rocker-project" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="the-rocker-project"><span class="header-section-number">14.4</span> The Rocker project</h2>
<p>The Rocker project offers a very large collection of “R-ready” Docker images that you can use as starting points for building your own Docker images. Before using these images though, I still need to explain one very important Docker concept. Let’s go back to our “Hello World” Docker image:</p>
<pre><code>FROM ubuntu:jammy

RUN uname -a</code></pre>
<p>The very first line, <code>FROM ubuntu:jammy</code> downloads an Ubuntu Jammy image, but from where? All these images get downloaded from <em>Docker Hub</em>, which you can browse <a href="https://hub.docker.com/">here</a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. If you create an account you can even push your own images on there. For example, we could push the image we built before, which we called <code>raps_ubuntu_r</code>, on Docker Hub. Then, if we wanted to create a new Docker image that builds upon <code>raps_ubuntu_r</code> we could simply type <code>FROM username:raps_ubuntu_r</code> (or something similar).</p>
<p>It’s also possible to not use Docker Hub at all, and share the image you built as a file. I’ll explain how later.</p>
<p>The Rocker project offers many different images, which are described <a href="https://rocker-project.org/images/">here</a><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. We are going to be using the <em>versioned</em> images. These are images that ship specific versions of R. This way, it doesn’t matter when the image gets build, the same version of R will be installed by getting built from source. Let me explain why building R from source is important. When we build the image from the Dockerfile we wrote before, R gets installed from the Ubuntu repositories. For this we use Ubuntu’s package manager and the following command: <code>apt-get install -y r-base</code>. As of writing, the version of R that gets installed is version 4.1.3. There’s two problems with installing R from Ubuntu’s repositories. First, we have to use whatever gets installed, which can be a problem with reproducibility. If we ran our analysis using R version 4.2.1, then we would like to dockerize that version of R. The second problem is that when we build the image today we get version 4.1.3. But it is not impossible that if we build the image in 6 months, we get R version 4.2.0, because it is likely that the version that ships in Ubuntu’s repositories will get updated at some point.</p>
<p>This means that depending on <em>when</em> we build the Docker image, we might get a different version of R. There are only two ways of avoiding this problem: either we build the image once and archive it and make sure to always keep a copy and ship that copy forever (or for as long as we want to make sure that pipeline is reproducible) just as you would ship data, code and any documentation required to make the pipeline reproducible. Or we write the Dockerfile in such a way that it always produces the same image, regardless of <em>when</em> it gets built. I very strongly advise you to go for the second option, but to <em>also</em> archive the image. But of course, this also depends on how critical your project is. Maybe you don’t need to start archiving images, or maybe you don’t even need to make sure that the Dockerfile always produces the same image. But I would still highly recommend that you write your Dockerfiles in such a way that they always output the same image. It is safer, and it doesn’t really mean extra work, thanks to the Rocker project.</p>
<p>So, let’s go back to the Rocker project, and specifically their <em>versioned</em> images which you can find <a href="https://rocker-project.org/images/versioned/r-ver.html">here</a><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. When you use one of the versioned images as a base for your project, you get the following guarantees:</p>
<ul>
<li>a fixed version of R that gets built from source. It doesn’t matter <em>when</em> you build the image, it will always ship with the same version of R;</li>
<li>the operating system will be the LTS release that was current when that specific version of R was current;</li>
<li>the R repositories are set to the Posit Public Package Manager (PPPM) at a specific date. This ensures that R packages don’t need to be compiled as PPPM serves binary packages for the amd64 architecture (which is the architecture that virtually all non-Apple computers use these days).</li>
</ul>
<p>This last point requires some more explanations. You should know that versioned Rocker images use the PPPM set at a specific date. This is a very neat feature of the PPPM. For example, the versioned Rocker image that comes with R 4.2.2 has the repos set at the 14th of March 2023, as you can see for yourself <a href="https://github.com/rocker-org/rocker-versioned2/blob/fb1d32e70061b0f978b7e35f9c68e2b79bafb69a/dockerfiles/r-ver_4.2.2.Dockerfile#L16">here</a><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. This means that if you use <code>install.packages("dplyr")</code> inside a container running from that image, then the version of <code>{dplyr}</code> that will get installed is the one that was available on the 14th of March.</p>
<p>This can be convenient in certain situations, and you may want, depending on your needs, to use the PPPM set a specific date to define Docker images, as the Rocker project does. You could even set the PPPM at a specific date for your main development machine (just follow the instructions <a href="https://packagemanager.rstudio.com/client/#/repos/2/overview">here</a><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>). But keep in mind that you will not be getting any updates to packages, so if you want to install a fresh version of a package that may introduce some nice new features, you’ll need to change the repos again. This is why I highly advise you to stay with your default repositories (or use r2u if you are on Ubuntu) and manage your projects’ package libraries using <code>{renv}</code>. This way, you don’t have to mess with anything, and have the flexibility to have a separate package library per project. The other added benefit is that you can then use the project’s <code>renv.lock</code> file to install the exact same package library inside the Docker image.</p>
<p>As a quick introduction to using Rocker images, let’s grab our pipeline’s <code>renv.lock</code> file which you can download from <a href="https://raw.githubusercontent.com/rap4all/housing/980a1b0cd20c60a85322dbd4c6da45fbfcebd931/renv.lock">here</a><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. This is the latest <code>renv.lock</code> file that we generated for our pipeline, it contains all the needed packages to run our pipeline, including the right versions of the <code>{targets}</code> package and the <code>{housing}</code> package that we developed. An important remark: it doesn’t matter if the <code>renv.lock</code> file contains packages that were released after the 14th of March. Even if the repositories inside the Rocker image that we will be using are set to that date, the lock file also specifies the URL of the right repository to download the packages from. So that URL will be used instead of the one defined for the Rocker image.</p>
<p>Another useful aspect of the <code>renv.lock</code> file is that it also records the R version that was used to originally develop the pipeline, in this case, R version 4.2.2. So that’s the version we will be using in our Dockerfile. Next, we need to check the version of <code>{renv}</code> that we used to build the <code>renv.lock</code> file. You don’t necessarily need to install the same version, but I recommend you do. For example, as I’m writing these lines, <code>{renv}</code> version 0.17.1 is available, but the <code>renv.lock</code> file was written by <code>{renv}</code> version 0.16.0. So to avoid any compatibility issues, we will also install the exact same version. Thankfully, that is quite easy to do (to check the version of <code>{renv}</code> that was used to write the lock file simply look for the word “renv” in the lock file).</p>
<p>While <code>{renv}</code> takes care of installing the right R packages, it doesn’t take care of installing the right system-level dependencies. So that’s why we need to install these system-level dependencies ourselves. I will give you a list of system-level dependencies that you can install to avoid any issues below, and I will also explain to you how I was able to come up with this list. It is quite easy thanks to Posit and their PPPM. For example, <a href="https://packagemanager.rstudio.com/client/#/repos/2/packages/tidyverse">here</a><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> is the summary page for the <code>{tidyverse}</code> package. If you select “Ubuntu 22.04 (Jammy)” on the top right, and then scroll down, you will see a list of dependencies that you can simply copy and paste into your Dockerfile:</p>
<figure class="figure">
<img src="images/tidyverse_jammy_deps.png" alt="System-level dependencies for the {tidyverse} package on Ubuntu." class="figure-img">
<figcaption class="figure-caption">
System-level dependencies for the {tidyverse} package on Ubuntu.
</figcaption>
</figure>
<p>We will use this list to install the required dependencies for our pipeline.</p>
<p>Create a new folder and call it whatever you want and save the <code>renv.lock</code> file linked above inside of it. Then, create an empty text file and call it Dockerfile. Add the following lines:</p>
<pre><code>FROM rocker/r-ver:4.2.2

RUN apt-get update &amp;&amp; apt-get install -y \
    libglpk-dev \
    libxml2-dev \
    libcairo2-dev \
    libgit2-dev \
    default-libmysqlclient-dev \
    libpq-dev \
    libsasl2-dev \
    libsqlite3-dev \
    libssh2-1-dev \
    libxtst6 \
    libcurl4-openssl-dev \
    libharfbuzz-dev \
    libfribidi-dev \
    libfreetype6-dev \
    libpng-dev \
    libtiff5-dev \
    libjpeg-dev \
    libxt-dev \
    unixodbc-dev \
    wget \
    pandoc

RUN R -e "install.packages('remotes')"

RUN R -e "remotes::install_github('rstudio/renv@0.16.0')"

RUN mkdir /home/housing

COPY renv.lock /home/housing/renv.lock

RUN R -e "setwd('/home/housing');renv::init();renv::restore()"</code></pre>
<p>The first line states that we will be basing our image on the image from the Rocker project that ships with R version 4.2.2, which is the right version that we need. Then, we install the required system-level dependencies using Ubuntu’s package manager, as previously explained. Then comes the <code>{remotes}</code> package. This will allow us to download a specific version from <code>{renv}</code> from Github, which is what we do in the next line. I want to stress again that I do this simply because the original <code>renv.lock</code> file was generated using <code>{renv}</code> version 0.16.0 and so to avoid any potential compatibility issues, I also use this one to restore the required packages for the pipeline. But it is very likely that I could have installed the current version of <code>{renv}</code> to restore the packages, and that it would have worked without problems. But just to be on the safe side, I install the right version of <code>{renv}</code>. By the way, I knew how to do this because I read <a href="https://rstudio.github.io/renv/articles/docker.html">this vignette</a><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> that explains all these steps (but I’ve only kept the absolute essential lines of code to make it work). Next comes the line <code>RUN mkdir /home/housing</code>, which creates a folder (<code>mkdir</code> stands for <em>make directory</em>), inside the Docker image, in <code>/home/housing</code>. On Linux distributions, <code>/home/</code> is the directory that users use to store their files, so I create the <code>/home/</code> folder and inside of it, I create a new folder, <code>housing</code> which will contain the files for my project. It doesn’t really matter if you keep that structure or not, you could skip the <code>/home/</code> folder if you wanted. What matters is that you put the files where you can find them.</p>
<p>Next comes <code>COPY renv.lock /home/housing/renv.lock</code>. This copies the <code>renv.lock</code> file from our computer (remember, I told you to save this file next to the Dockerfile) to <code>/home/housing/renv.lock</code>. By doing this, we include the <code>renv.lock</code> file inside of the Docker image which will be crucial for the next and final step: <code>RUN R -e "setwd('/home/housing');renv::init();renv::restore()"</code>.</p>
<p>This runs the <code>R</code> program from the Linux command line with the option <code>-e</code>. This option allows you to pass an <code>R</code> expression to the command line, which needs to be written between <code>""</code>. Using <code>R -e</code> will quickly become an habit, because this is how you can run R non-interactively, from the command line. The expression we pass sets the working directory to <code>/home/housing</code>, and then we use <code>renv::init()</code> and <code>renv::restore()</code> to restore the packages from the <code>renv.lock</code> file that we copied before. Using this Dockerfile, we can now build an image that will come with R version 4.2.2 pre-installed as well as all the same packages that we used to develop the <code>housing</code> pipeline.</p>
<p>Build the image using <code>docker build -t housing_image .</code> (don’t forget the <code>.</code> at the end).</p>
<p>The build process will take some time, so I would advise you to go get a hot beverage in the meantime. Now, we did half the work: we have an environment that contains the required software for our pipeline, but the pipeline files themselves are missing. But before adding the pipeline itself, let’s see if the Docker image we built is working. For this, log in to a command line inside a running Docker container started from this image with this single command:</p>
<pre><code>docker run --rm -it --name housing_container housing_image bash</code></pre>
<p>This starts <code>bash</code> (Ubuntu’s command line) inside the <code>housing_container</code> that gets started from the <code>housing_image</code> image. We add the <code>--rm</code> flag do <code>docker run</code>, this way the Docker container gets stopped when we log out (if not, then the Docker container will continue running in the background). Once logged in, we can move to the folder’s project using:</p>
<pre><code>user@docker ➤ cd home/housing</code></pre>
<p>and then start the R interpreter:</p>
<pre><code>user@docker ➤ R</code></pre>
<p>if everything goes well, you should see the familiar R prompt with a message from <code>{renv}</code> at the end:</p>
<pre><code>R version 4.2.2 (2022-10-31) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

* Project '/home/housing' loaded. [renv 0.16.0]</code></pre>
<p>Try to load the <code>{housing}</code> package with <code>library("housing")</code>. This should work flawlessly!</p>
</section>
<section id="dockerizing-projects" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="dockerizing-projects"><span class="header-section-number">14.5</span> Dockerizing projects</h2>
<p>So we now have a Docker image that has the right environment for our project. We can now dockerize the project itself. There are two ways to do this: we either simply add the required lines to our Dockerfile, meaning copying the <code>_targets.R</code> script to the Docker image at build time and then use <code>targets::tar_make()</code> to run the pipeline, or we now create a new Dockerfile that will build upon this image and add the required lines there. In this section, we will use the first approach, and in the next section, we will use the second. The advantage of the first approach is that we have a single Dockerfile, and everything we need is right there. Also, each Docker image is completely tailor-made for each project. The issue is that building takes some time, so if for every project we restart from scratch it can be tedious to have to wait for the build process to be done (especially if you use continuous integration, as we shall see in the next chapter).</p>
<p>The advantage of the second approach is that we have a base that we can keep using for as long as we want. You will only need to wait once for R and the required packages to get installed. Then, you can use this base for any project that requires the same version of R and packages. This is especially useful if you don’t update your development environment very often, and develop a lot of projects with it.</p>
<p>In summary, the first approach is “dockerize pipelines”, and the second approach is “dockerize the dev environment and use it for many pipelines”. It all depends on how you work: in research, you might want to go for the first approach, as each project likely depends on bleeding-edge versions of R and packages. But in industry, where people tend to put the old adage “if ain’t broke don’t fix it” into practice, dev environments are usually frozen for some time and only get updated when really necessary (or according to a fixed schedule).</p>
<p>To dockerize the pipeline, we first need to understand something important with Docker, which I’ve already mentioned in passing: a Docker image is an immutable sandbox. This means that we cannot change it at run-time, only at build-time. So if we log in to a running Docker container (as we did before), and install an R package using <code>install.packages("package_name")</code>, that package will disappear if we stop that container. The same is true for any files that get created at run-time: they will also disappear once the container is stopped. So how are we supposed to get the outputs that our pipeline generates from the Docker container? For this, we need to create a volume. A volume is nothing more than a shared folder between the Docker container and the host machine that starts the container. We simply need to specify the path for this shared folder when running the container, and that’s it.</p>
<p>Let’s first write a Dockerfile that contains all the necessary files. We simply need to add the <code>_targets.R</code> script from our pipeline, the <code>analyse_data.Rmd</code> markdown file and all the functions from the <code>functions/</code> folder (you can find all the required files <a href="https://github.com/rap4all/housing/tree/pipeline">here</a><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>):</p>
<pre><code>FROM rocker/r-ver:4.2.2

RUN apt-get update &amp;&amp; apt-get install -y \
    libglpk-dev \
    libxml2-dev \
    libcairo2-dev \
    libgit2-dev \
    default-libmysqlclient-dev \
    libpq-dev \
    libsasl2-dev \
    libsqlite3-dev \
    libssh2-1-dev \
    libxtst6 \
    libcurl4-openssl-dev \
    libharfbuzz-dev \
    libfribidi-dev \
    libfreetype6-dev \
    libpng-dev \
    libtiff5-dev \
    libjpeg-dev \
    libxt-dev \
    unixodbc-dev \
    wget \
    pandoc

RUN R -e "install.packages('remotes')"

RUN R -e "remotes::install_github('rstudio/renv@0.16.0')"

RUN mkdir /home/housing

RUN mkdir /home/housing/pipeline_output

RUN mkdir /home/housing/shared_folder

COPY renv.lock /home/housing/renv.lock

COPY functions /home/housing/functions

COPY analyse_data.Rmd /home/housing/analyse_data.Rmd

COPY _targets.R /home/housing/_targets.R

RUN R -e "setwd('/home/housing');renv::init();renv::restore()"

RUN cd /home/housing &amp;&amp; R -e "targets::tar_make()"

CMD mv /home/housing/pipeline_output/* /home/housing/shared_folder/</code></pre>
<p>I’ve added some <code>COPY</code> statements to copy the files from our computer to the Docker image, and also created some new directories: the <code>pipeline_output</code> and the <code>shared_folder</code> directories. <code>pipeline_output</code> is the folder that will contain all the outputs from the pipeline, and <code>shared_folder</code> (you guessed it) will be the folder that we will use to save the outputs of the pipeline to our computer.</p>
<p>I then use <code>targets::tar_make()</code> to run the pipeline, but I first need to use <code>cd /home/housing</code> to change directories to the project’s folder. This is because in order to use the library that <code>{renv}</code> installed, we need to start the R session in the right directory. So we move to the right directory, then we run the pipeline using <code>R -e "targets::tar_make()"</code>. Notice that we do both operations within a <code>RUN</code> statement. This means that the pipeline will run at build-time (remember, <code>RUN</code> statements run at build-time, <code>CMD</code> statements at run-time). In order words, the image will contain the outputs. This way, if the build process and the pipeline take a long time to run, you can simply leave them running overnight for example. In the morning, while sipping on your coffee, you can then simply run the container to instantly get the outputs. This is because we move the outputs of the pipeline from the folder <code>pipeline_output</code> to the <code>shared_folder</code> folder using a <code>CMD</code> statament. Thus, when we run the container, the outputs get moved into the shared folder, and we can retrieve them.</p>
<p>One last thing I had to do: I needed to change the last target in the <code>_targets.R</code> script. Before dockerizing it, it was like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tar_render</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  analyse_data,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"analyse_data.Rmd"</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>but I had to change it to this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tar_render</span>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  analyse_data,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"analyse_data.Rmd"</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">output_dir =</span> <span class="st">"/home/housing/pipeline_output"</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The argument to <code>output_dir</code> gets passed to <code>knitr::knit()</code> and simply states that the output files should be saved in that folder. I can now build the image using <code>docker build -t housing_image .</code>. Once the build process is done, we can log in to the container to see if our files are there. But let me repeat again, that you are not really supposed to do so. You could simply run the container now and get your files. But let’s just take a quick look. You can log in to a bash session using:</p>
<pre><code>owner@localhost ➤ docker run --rm -it --name housing_container housing_image bash</code></pre>
<p>If you then move to <code>/home/housing/pipeline_output</code> and run <code>ls</code> in that folder, you should see <code>analyse_data.html</code>. That’s our output! So how do we get it out?</p>
<p>You need to run the container with the <code>-v</code> flag which allows you to specify the path to the shared folder on your computer, and the shared folder inside the Docker container. The code below shows how to do it (I’ve used the <code>\</code> to break this long command over two lines):</p>
<pre><code>owner@localhost ➤ docker run --rm --name housing_container -v \
                  /host/path/to/shared_folder:/home/housing/shared_folder:rw \
                  housing_image</code></pre>
<p><code>/host/path/to/shared_folder</code> is the path to the shared folder on my computer. <code>/home/housing/shared_folder</code> is the path to the shared folder inside the Docker container. When these lines run, the very last <code>CMD</code> statement from the Dockerfile runs, moving the contents from inside the Docker container to our computer. If you check the contents of the <code>shared_folder</code> on your computer, you will see <code>analyse_data.html</code> in there.</p>
<p>That’s it, we have now a complete reproducible analytical pipeline. We managed to tick every one of the following boxes when running our pipeline:</p>
<ul>
<li>Same version of R that was used for development;</li>
<li>Same versions of all the packages that were used for development;</li>
<li>The whole stack runs on a “frozen” environment;</li>
<li>We can reproduce this environment (but more on that later…).</li>
</ul>
<p>We now need to share all this with the world. One simple solution is to share the Dockerfile on Github. For example, <a href="https://github.com/rap4all/housing/tree/docker">this is the repository</a><a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> with all the required code to build the Docker image and run the pipeline. But we could also share the built image so that users only need to run the pipeline to instantly get the results. In the next section, we will learn about dockerizing development environments, and then see how we can share images that have already been built.</p>
</section>
<section id="dockerizing-development-environments" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="dockerizing-development-environments"><span class="header-section-number">14.6</span> Dockerizing development environments</h2>
<section id="creating-a-base-image-for-development" class="level3" data-number="14.6.1">
<h3 data-number="14.6.1" class="anchored" data-anchor-id="creating-a-base-image-for-development"><span class="header-section-number">14.6.1</span> Creating a base image for development</h3>
<p>In the previous section, I mentioned that you could either “dockerize pipelines” or “dockerize the dev environment and use it for many pipelines”. What we learned up until now was how to dockerize one single pipeline. In this section, we will learn how to build and dockerize an environment, and then build pipelines that use these environment as starting points.</p>
<p>Let me first explain, again, why (or when) you might want to use his approach instead of the “dockerizing pipelines” approach.</p>
<p>Depending on what or where you work, it is sometimes necessary to have a stable development environment that only gets rarely updated (following a strict schedule). In my own experience, when I was doing research I was almost always using the latest R version and packages. When I’ve joined the private sector, we worked on an environment that we developers could not update ourselves. That environment was updated according to a fixed schedule and now that I’m back in the public sector (but not doing research), I work in a similar manner, on a “frozen” environment. Working on frozen environments like this minimizes the unexpected issues that frequent updates can bring. So how can we use Docker to use such an approach?</p>
<p>The idea is to split up the Dockerfile we used in the previous section into two parts. The first part would consist in setting up everything that is “OS-related”. So installing R, packages, and system-level dependencies. The second Dockerfile would use the image defined thanks to the first Dockerfile as a base and then add the required lines to obtain the results from the pipeline. The first image, that focuses on the operating system, can be archived and re-used for as long as required to keep building pipelines. Once we update our environment, we can then re-generate a new Docker image that reflects this update.</p>
<p>Let’s do this now. The first image would simply consist of these lines:</p>
<pre><code>FROM rocker/r-ver:4.2.2

RUN apt-get update &amp;&amp; apt-get install -y \
    libglpk-dev \
    libxml2-dev \
    libcairo2-dev \
    libgit2-dev \
    default-libmysqlclient-dev \
    libpq-dev \
    libsasl2-dev \
    libsqlite3-dev \
    libssh2-1-dev \
    libxtst6 \
    libcurl4-openssl-dev \
    libharfbuzz-dev \
    libfribidi-dev \
    libfreetype6-dev \
    libpng-dev \
    libtiff5-dev \
    libjpeg-dev \
    libxt-dev \
    unixodbc-dev \
    wget \
    pandoc

RUN R -e "install.packages('remotes')"

RUN R -e "remotes::install_github('rstudio/renv@0.16.0')"</code></pre>
<p>This image can then be built using <code>docker build -t dev_env_r .</code> (if you followed along, the cache will be used and this image should get built instantly). This simply installs all the packages and system-level dependencies that are common and needed for all pipelines. Then, each specific package libraries that are required for each pipeline will get installed using the pipeline-specific <code>renv.lock</code> file. This will be done with a second Dockerfile. But first, we need to make the <code>dev_env_r</code> image available to others, such that it becomes possible to build new images upon <code>dev_env_r</code>. There are two ways to make images available to anyone: either online through <a href="https://hub.docker.com/">Docker Hub</a> (in case there’s nothing preventing you from sharing the development environment through Docker Hub) or locally, by compressing the images and sharing them internally (in case you don’t want to share your images with the world, because they contain proprietary software that you’ve developed within your company for example). I want to stress that making the image available through Docker Hub is different from sharing the Dockerfile through Github. You could just share the Dockerfiles through Github, and then tell users to first build the dev environment, and then build the pipeline image by building the second, pipeline-specific Dockerfile. But by sharing a built image from Docker Hub, users (including future you) will only need to build the pipeline-specific image and this is much faster. Just like we used <code>FROM ubuntu:jammy</code> in our Dockerfiles before, we will now use something like <code>FROM my_repo/my_image:version_number</code> from now on.</p>
<p>In the next section I will discuss sharing images on Docker Hub, but before that, let me first address the elephant in the room: the development environment that you are using may not be the one you are dockerizing. For example, if you are using Windows or macOS on your computer, then the environment that you are dockerizing will be different since it will be based on Ubuntu. There are only three solutions to this conundrum:</p>
<ul>
<li>You don’t care, and maybe that’s fine. As I stated multiple times, the same pipeline outputting different results due to different operating systems is in practice rare (but it can happen);</li>
<li>You prefer being safe than sorry, and install Ubuntu on your pc as well. This is very often not an acceptable solution, however.</li>
<li>You develop on your host environment, but after you’re done you compare the results obtained from the Docker container to those obtained on your development environment.</li>
<li>You use the Docker image not only to ship RAPs, but also for development.</li>
</ul>
<p>The last option implies that you use Docker interactively, which is not ideal, but it is possible. For example, you could install RStudio server and run a Dockerized version of RStudio from a running Docker container. This is actually what happens if you follow the instructions on the Rocker project’s homepage. You can get a dockerized RStudio instance by running:</p>
<pre><code>docker run --rm -ti -e PASSWORD=yourpassword -p 8787:8787 rocker/rstudio</code></pre>
<p>and then going to <code>http://localhost:8787</code> on your web-browser. You can then log in with the username “rstudio” and the password “yourpassword”. But you would also need to mount a volume (I called it “shared folder” previously) to keep the files you edit on your computer (remember, Docker container are immutable, so any files created within a Docker container will be lost when it’s stopped). Overall, I think that this is too cumbersome, especially because the risks of getting different results only because of your operating system are very, very, very low. I would simply advise the following:</p>
<ul>
<li>Use the same version of R on your computer and on Docker;</li>
<li>Use the same package library on your computer and on Docker by using the same <code>renv.lock</code> file.</li>
</ul>
<p>By following these two rules, you should keep any issues to a minimum. When or if you need to update R and/or the package library on your machine, simply create a new Docker image that reflects these changes.</p>
<p>However, if work in a field where operating system versions matter, then yes, you should find a way to either use the dockerized environment for development, or you should install Ubuntu on your computer (the same version as in Docker of course).</p>
<p>Let’s now discuss sharing images.</p>
</section>
<section id="sharing-images-through-docker-hub" class="level3" data-number="14.6.2">
<h3 data-number="14.6.2" class="anchored" data-anchor-id="sharing-images-through-docker-hub"><span class="header-section-number">14.6.2</span> Sharing images through Docker Hub</h3>
<p>If you want to share Docker images through Docker Hub, you first need to create a free account. A free account gives you unlimited public repositories. If you want to make your images private, you need a paid account. For our purposes though, a free account is more than enough. Again, in the next section, we will discuss how you can build new images upon other images without using Docker Hub.</p>
<p>If you want to follow along, make sure that you have also written a Dockerfile and built an image that you can upload on Docker Hub. I will be uploading the image <code>dev_env_r</code> to Docker Hub, so if you want you could use for your own projects.</p>
<p>If you built an image to upload, now is the right moment to talk about the <code>docker images</code> command. This will list all the images available on your computer. You should see something like this:</p>
<pre><code>REPOSITORY         TAG       IMAGE ID       CREATED       SIZE
rver_intro         latest    d3764d067534   2 days ago    1.61GB
dev_env_r          latest    92fcf973ba42   2 days ago    1.42GB
raps_ubuntu_r      latest    7dabadf3c7ee   4 days ago    1.04GB
rocker/tidyverse   4.2.2     545e4538a28a   3 weeks ago   2.19GB
rocker/r-ver       4.2.2     08942f81ec9c   3 weeks ago   824MB</code></pre>
<p>Take note of the image id of the <code>dev_env_r</code> image (second line), we will use it to push our image to Docker Hub. Also, don’t be alarmed by the size of the images, because this is a bit misleading. Different images that use the same base (so here Ubuntu Jammy), will reuse “layers” such that they don’t actually take up the size that is printed by <code>docker images</code>. So if images A and B both use Ubuntu Jammy as a base, but image A has RStudio installed and B also RStudio but Python as well, most of the space that A and B take up will be shared. The only difference will be that B will need a little bit more space for Python.</p>
<p>You can also list the running containers with <code>docker container ls</code> (or <code>docker ps</code>). If a container is running you should see something like this:</p>
<pre><code>CONTAINER ID   IMAGE              COMMAND   CREATED
545e4538a28a   rocker/tidyverse   "/init"   3 minutes ago

STATUS         PORTS                                       NAMES
Up 3 minutes   0.0.0.0:8787-&gt;8787/tcp, :::8787-&gt;8787/tcp   elastic_morse</code></pre>
<p>You can stop the container by running <code>docker stop CONTAINER ID</code>. So, list the images again using <code>docker images</code>. Take note of the image id of the image you want to push to Docker Hub.</p>
<p>Now, log in to Docker Hub using <code>docker login</code> (yes, from your terminal). You will be asked for your credentials, and if log in is successful, you see a message <code>Log In Succeeded</code> in your terminal (of course, you need first to have an account on Docker Hub).</p>
<p>Now, you need to tag the image (this gives it a version number). So you would write something like:</p>
<pre><code>owner@localhost ➤ docker tag IMAGE_ID your_username_on_docker_hub/your_image:version1</code></pre>
<p>so in my case, it would be:</p>
<pre><code>owner@localhost ➤ docker tag 92fcf973ba42 rap4all/dev_env_r:4.2.2</code></pre>
<p>Next, I need to push it using <code>docker push</code>:</p>
<pre><code>owner@localhost ➤ docker push rap4all/dev_env_r:4.2.2</code></pre>
<pre><code>owner@localhost $ docker push rap4all/dev_env_r:4.2.2</code></pre>
<p>You can go check your profile and your repositories, you should see your image there. In my case, you can find the image <a href="https://hub.docker.com/layers/rap4all/dev_env_r/4.2.2/images/sha256-a961d6b11bc1fb3ead5cfcd82e24d3cfbce763fda0efce62f8b0abb319e80160?context=repo">here</a>.</p>
<p>This image can now be used as a stable base for developing our pipelines. Here’s how I can now use this base image for my <code>housing</code> pipeline:</p>
<pre><code>FROM rap4all/dev_env_r:4.2.2

RUN mkdir /home/housing

RUN mkdir /home/housing/pipeline_output

RUN mkdir /home/housing/shared_folder

COPY renv.lock /home/housing/renv.lock

COPY functions /home/housing/functions

COPY analyse_data.Rmd /home/housing/analyse_data.Rmd

COPY _targets.R /home/housing/_targets.R

RUN R -e "setwd('/home/housing');renv::init();renv::restore()"

RUN cd /home/housing &amp;&amp; R -e "targets::tar_make()"

CMD mv /home/housing/pipeline_output/* /home/housing/shared_folder/</code></pre>
<p>Take a look at this Dockerfile’s first line: <code>FROM rap4all/dev_env_r:4.2.2</code>. This is different from before, where I pulled from <code>ubuntu:jammy</code>. Now I’m re-using the image that defines the development environment, and I can do so for as many projects as necessary. In time, I could update to a newer version of R, if required. But R and (Ubuntu) being quite stable, as long as I can install the packages required for my projects, I can keep using it for years (and LTS versions of Ubuntu like Jammy get supported for 5 years).</p>
<p>If you want to test this, you could delete all images and containers from your system. This way, when you will build the image using the above Dockerfile, it will have to pull from Docker Hub. To delete all containers, start by using <code>docker system prune</code>. You can then delete all images using <code>docker rmi $(docker images -a -q)</code>. This should remove everything. Now, let’s build the image using the above Dockerfile using <code>docker build -t housing_image .</code> (don’t forget to add the necessary files for the build process to succeed, <code>renv.lock</code>, <code>_targets.R</code>, <code>analyse_data.Rmd</code> and the <code>functions</code> folder). You should see the image getting pulled from Docker Hub and then the build process resuming and the pipeline running.</p>
<p>In the next section, I’ll explain to you how you can re-use base images like we just did, but without using Docker Hub, in case you cannot, or do not want, to rely on it.</p>
</section>
<section id="sharing-a-compressed-archive-of-your-image" class="level3" data-number="14.6.3">
<h3 data-number="14.6.3" class="anchored" data-anchor-id="sharing-a-compressed-archive-of-your-image"><span class="header-section-number">14.6.3</span> Sharing a compressed archive of your image</h3>
<p>If you can’t upload the image on Docker Hub, you can still “save it” into a file and share that file instead (internally to your institution/company).</p>
<p>Run <code>docker save</code> to save the image into a file:</p>
<pre><code>owner@localhost ➤ docker save dev_env_r &gt; dev_env_r.tar</code></pre>
<p>This will create a <code>.tar</code> file of the image. You can then compress this file with an archiving tool if you want. If you’re on Linux, you could do so in one go (this will take some time):</p>
<pre><code>owner@localhost ➤ docker save dev_env_r | gzip &gt; dev_env_r.tgz</code></pre>
<p>If you want to load this image, use <code>docker load</code>:</p>
<pre><code>owner@localhost ➤ docker load &lt; dev_env_r.tar</code></pre>
<p>you should see an output like this:</p>
<pre><code>202fe64c3ce3: Loading layer [======================&gt;]  80.33MB/80.33MB
e7484d5519b7: Loading layer [======================&gt;]  6.144kB/6.144kB
a0f5608ee4a8: Loading layer [======================&gt;]  645.4MB/645.4MB
475d1d69813f: Loading layer [======================&gt;]  102.9kB/102.9kB
d7963749937d: Loading layer [======================&gt;]  108.9MB/108.9MB
224a0042a76f: Loading layer [======================&gt;]    600MB/600MB
a75e978c1654: Loading layer [======================&gt;]  605.7kB/605.7kB
7efc10233531: Loading layer [======================&gt;]  1.474MB/1.474MB
Loaded image: dev_env_r:latest
</code></pre>
<p>or if you compressed the file on Linux, you can also use:</p>
<pre><code>owner@localhost ➤ docker load -i dev_env_r.tgz</code></pre>
<p>to load the archive.</p>
<p>You can then use <code>dev_env_r</code> for a pipeline by using this <code>FROM</code> statement in your Dockerfile:</p>
<pre><code>FROM dev_env_r</code></pre>
<p>Since the image is available locally, it’ll get used instead of pulling it from Docker Hub. So in case you cannot use Docker Hub, you could build the base images, compress them, and share them on your corporate network. Then, people can simply download them and load them and build new images on top of them.</p>
<p>So in summary, here’s how you can share images with the world, your colleagues, or future you:</p>
<ul>
<li>Only share the Dockerfiles. Users need to build the images.</li>
<li>Share images on Docker Hub. It’s up to you if you want to share a base image with the required development environment, and then separate, smaller images for the pipelines, or if you want to share a single image which contains everything.</li>
<li>Share images but only within your workplace.</li>
</ul>
<p>Whatever option you go for, I hope that I’ve convinced you that Docker is really convenient. It may look complicated at first, but it saves a lot of headaches in the long run. Let me finish this section by stating something plainly: up until now, I tried to sell to you the idea that reproducibility did not require any extra effort, if you simply used the tools and techniques discussed in this book right from the start, with the added benefit of improving the quality of the code of your pipeline. I truly believe this to be the case with everything that I’ve shown up until now, but Docker. Using Docker for reproducibility does require some extra effort. However, if your projects require reproducibility, and you really want to play it safe, I think that Docker is unavoidable. It takes time to set up, but once it’s done, you do not have to think about the infrastructure anymore and can focus on developing. Also, if you need to maintain your pipeline and keep running it against newer and newer versions of R, you simply need to change one line (the <code>FROM</code> statement, for example, from Ubuntu Jammy to Ubuntu 24.04, the next LTS) in the Dockerfile to update everything to the latest version of R.</p>
<p>But, there is still a “little” issue, that I’m discussing in the next section.</p>
</section>
</section>
<section id="some-issues-of-relying-on-docker" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="some-issues-of-relying-on-docker"><span class="header-section-number">14.7</span> Some issues of relying on Docker</h2>
<section id="the-problems-of-relying-so-much-on-docker" class="level3" data-number="14.7.1">
<h3 data-number="14.7.1" class="anchored" data-anchor-id="the-problems-of-relying-so-much-on-docker"><span class="header-section-number">14.7.1</span> The problems of relying so much on Docker</h3>
<p>So we now know how to build truly reproducible analytical pipelines, but let’s be blunt, relying entirely on one single tool, Docker, is a bit of an issue… it’s a single point of failure. But the problem is not Docker itself, but the infrastructure.</p>
<p>Let me explain: Docker is based on many different open-source parts, and that’s great. This means that even if the company behind Docker ruins it by taking some weird decisions, we have alternatives that build upon the open-source parts of Docker. There’s Podman, which is a drop-in replacement (when combined with other tools) made by Red Hat, which is completely open-source as well. So the risk does not come from there, because even if for some reason Docker would disappear, or get abandoned or whatever, we could still work with Podman, and it would also be technically possible to create a fork from Docker.</p>
<p>But the issue is the infrastructure. For now, using Docker and more importantly hosting images is free for personal use, education, open-source communities and small businesses. So this means that a project like Rocker likely pays nothing for hosting all the images they produce (but who knows, I may be wrong on this). Docker recently announced that they would abandon their <em>Docker Free Team subscription</em> plans that some open-source organizations use, and that they should upgrade to a paid subscription within 30 days. So it is not unreasonable to think that free users with a free account might also be forced to pay one day. Don’t get me wrong, I’m not saying that Docker is not allowed to make money. But it is something that you need to keep in mind in case you cannot afford a subscription (and who knows how much it’s going to cost). This is definitely a risk that needs mitigation, and a plan B. This plan B could be to host the images yourself, by saving them using <code>docker save</code>. Or you could even self-host an image registry (or lobby your employer/institution/etc to host a registry for its developers/data scientists/researchers). In any case, it’s good to have options and now what potential risks using this technology entail.</p>
</section>
<section id="is-docker-enough" class="level3" data-number="14.7.2">
<h3 data-number="14.7.2" class="anchored" data-anchor-id="is-docker-enough"><span class="header-section-number">14.7.2</span> Is Docker enough?</h3>
<p>I would say that for 99% of applications, yes, Docker is enough for building RAPs. But strictly speaking, using a Dockerfile which installs a specific version of R and uses <code>{renv}</code> to install specific versions of packages and use an LTS release of Ubuntu, we could end up with two different images. This is because Ubuntu gets updated, so if you build an image in the beginning of 2022 and then once again in 2023, the system-level libraries will be different. So strictly speaking, you end up with two different images, and it’s not absolutely impossible that this may impact your pipeline. So ideally, we would also need a way to always install the same system-level dependencies, regardless of when we build the image. There is a package manager called Nix that makes this possible, but this is outside the scope of this book. The reason is that, again, in practice if you use an LTS release you should be fine. But if you really require <em>bitwise reproducibility</em> (i.e., two runs of the same pipeline will yield the same result to the last bit), then yes, you should definitely look into Nix (and who knows, I might write a book just about that titled <em>Building bitwise reproducible analytical pipelines (braps) using Nix</em>).</p>
<p>Another issue with Docker is that images can be quite opaque, especially if you define images that pull from images that pull themselves from other images… Just look at our pipeline: it pulls from <code>dev_env_r</code>, which pulls from <code>rocker:4.2.2</code> which pulls itself from the official Ubuntu Jammy image. So to be fully transparent, we would need to link to all the Dockerfiles, or rewrite one big Dockerfile that pulls from Ubuntu Jammy only.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">14.8</span> Conclusion</h2>
<p>This book could stop here. We have learned the following things:</p>
<ul>
<li>version control;</li>
<li>functional programming;</li>
<li>literate programming;</li>
<li>package development;</li>
<li>testing;</li>
<li>build automation;</li>
<li>“basic” reproducibility using <code>{renv}</code>;</li>
<li>“total” reproducibility using Docker.</li>
</ul>
<p>It is now up to you to select the tools that are most relevant for your projects. You might not need to package code for example. Or maybe literate programming is irrelevant to your needs. But it is difficult to argue against Docker. If you need to keep re-running a pipeline for some years, Docker is (almost) the only option available (unless you dedicate an entire physical machine to running that pipeline and never, ever, again touch that machine).</p>
<p>In the next and final chapter, we will learn some basics about continuous integration with Github Actions, which will allow us to automate even the building of Docker images and running pipelines.</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>https://rocker-project.org/<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://hub.docker.com/<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>https://rocker-project.org/images/<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>https://rocker-project.org/images/versioned/r-ver.html<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>https://is.gd/fdrq4p<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>https://is.gd/jbdTKC<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>https://is.gd/5UcuxW<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>https://is.gd/ZaXHwa<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>https://rstudio.github.io/renv/articles/docker.html<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>https://github.com/rap4all/housing/tree/pipeline<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>https://github.com/rap4all/housing/tree/docker<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./targets.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Build automation with targets</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ci_cd.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Continuous integration and continuous deployment</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>